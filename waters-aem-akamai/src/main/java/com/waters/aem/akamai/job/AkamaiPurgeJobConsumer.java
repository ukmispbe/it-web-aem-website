package com.waters.aem.akamai.job;

import com.google.common.base.Stopwatch;
import org.apache.sling.api.SlingConstants;
import org.apache.sling.event.jobs.Job;
import org.apache.sling.event.jobs.consumer.JobConsumer;
import org.osgi.service.component.annotations.Component;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.concurrent.TimeUnit;

/**
 * The Solr Index Job Consumer is responsible for consuming indexing events generated by the Solr replication listener.
 * Unsuccessful jobs may be retried up to the number of retries allowed by the job queue configuration.
 */
@Component(immediate = true,
    service = JobConsumer.class,
    property = {
        JobConsumer.PROPERTY_TOPICS + "=" + AkamaiPurgeJobConsumer.JOB_TOPIC
    })
public final class AkamaiPurgeJobConsumer implements JobConsumer {

    public static final String JOB_TOPIC = "com/waters/events/akamai/purge";

    private static final Logger LOG = LoggerFactory.getLogger(AkamaiPurgeJobConsumer.class);

    /**
     * Process the indexing job via the Akamai Purge service.
     *
     * @param job purge job
     * @return OK job result if successful, CANCEL result if unsuccessful
     */
    @Override
    public JobResult process(final Job job) {
        final Stopwatch stopwatch = Stopwatch.createStarted();

        final String path = job.getProperty(SlingConstants.PROPERTY_PATH, String.class);

        LOG.info("processing akamai purge job for path : {}", path);

        boolean success;

        try {
            // TODO
            success = true;
        } catch (Exception e) {
            // re-throw exception to cancel the job
            throw new RuntimeException(e);
        }

        final long duration = stopwatch.elapsed(TimeUnit.SECONDS);
        final JobResult result = success ? JobResult.OK : JobResult.CANCEL;

        LOG.info("finished processing akamai purge job in {}s with result : {}", duration, result.name());

        return result;
    }
}
